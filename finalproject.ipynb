{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 4604 Final Project - Predicting if cancer is benign or not\n",
    "\n",
    "## Amogh Jahagirdar and Ryan Rouleau\n",
    "\n",
    "Dataset: [https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/home](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precursor Analysis/General Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:09:03.050873Z",
     "start_time": "2018-12-15T22:09:02.190110Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:09:03.170183Z",
     "start_time": "2018-12-15T22:09:03.054719Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean     ...       texture_worst  perimeter_worst  \\\n",
       "count     569.000000     ...          569.000000       569.000000   \n",
       "mean        0.181162     ...           25.677223       107.261213   \n",
       "std         0.027414     ...            6.146258        33.602542   \n",
       "min         0.106000     ...           12.020000        50.410000   \n",
       "25%         0.161900     ...           21.080000        84.110000   \n",
       "50%         0.179200     ...           25.410000        97.660000   \n",
       "75%         0.195700     ...           29.720000       125.400000   \n",
       "max         0.304000     ...           49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:09:03.189955Z",
     "start_time": "2018-12-15T22:09:03.174176Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop last column (\"Unnamed:32\" column of NaNs being read, when the CSV is opened up in Excel that column doesn't exist)\n",
    "data_cleaned = data.iloc[:, :-1]\n",
    "\n",
    "# Drop ID (just a bookeeping column part of the original data)\n",
    "data_cleaned = data_cleaned.drop(\"id\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:29:53.642374Z",
     "start_time": "2018-12-15T23:29:53.612801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentages of benign and maligant data is \n",
      " B    62.741652\n",
      "M    37.258348\n",
      "Name: diagnosis, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analyze the balance of the data.\n",
    "nrows = data_cleaned.shape[0]\n",
    "print(\"Percentages of benign and maligant data is \\n {}\".format(100 * data_cleaned[\"diagnosis\"].value_counts()/nrows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, there are significantly more benign cases than malignant in the given dataset which could effect our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:30:14.020294Z",
     "start_time": "2018-12-15T23:30:14.003982Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and testing sets\n",
    "X = data_cleaned[data_cleaned.columns.difference([\"diagnosis\"])]\n",
    "y = data_cleaned['diagnosis']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "Next, we will create a simple baseline classifier with no feature extraction. We can use scikit learn's DummyClassifier class with \"the most frequent\" strategy. This is not used for actual classification purposes, it is mereley a benchmark for what a theoretical classifier would predict if it didn't actually learn from the features in the data (a minimum accuracy for our actual models). All of our models should perform much better than the DummyClasifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:09:03.272309Z",
     "start_time": "2018-12-15T22:09:03.257989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Training accuracy: 0.629108\n",
      "Baseline Testing accuracy: 0.622378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "baseline = DummyClassifier(strategy='most_frequent', random_state=1234)\n",
    "baseline.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Baseline Training accuracy: %0.6f\" % accuracy_score(Y_train, baseline.predict(X_train)))\n",
    "print(\"Baseline Testing accuracy: %0.6f\" % accuracy_score(Y_test, baseline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our models should be able to perform significantly above 60% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Baseline Classification Algorithms (No feature selection, preprocessing, or hyperparameter tuning)\n",
    "###  Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:09:03.698671Z",
     "start_time": "2018-12-15T22:09:03.663506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Decision Tree Training accuracy: 1.000000\n",
      "Baseline Decision Tree Testing accuracy: 0.958042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisionTree = DecisionTreeClassifier(random_state=1234)\n",
    "decisionTree.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Baseline Decision Tree Training accuracy: %0.6f\" % accuracy_score(Y_train, decisionTree.predict(X_train)))\n",
    "print(\"Baseline Decision Tree Testing accuracy: %0.6f\" % accuracy_score(Y_test, decisionTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:09:04.458445Z",
     "start_time": "2018-12-15T22:09:04.280417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Logistic Regression Training accuracy: 0.948357\n",
      "Baseline Logistic Regression Testing accuracy: 0.986014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression = LogisticRegression(random_state=1234)\n",
    "logisticRegression.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Baseline Logistic Regression Training accuracy: %0.6f\" % accuracy_score(Y_train, logisticRegression.predict(X_train)))\n",
    "print(\"Baseline Logistic Regression Testing accuracy: %0.6f\" % accuracy_score(Y_test, logisticRegression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:09:04.921997Z",
     "start_time": "2018-12-15T22:09:04.886114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Support Vector Machine Training accuracy: 1.000000\n",
      "Baseline Support Vector Machine Testing accuracy: 0.622378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "svm = SVC(random_state=1234)\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Baseline Support Vector Machine Training accuracy: %0.6f\" % accuracy_score(Y_train, svm.predict(X_train)))\n",
    "print(\"Baseline Support Vector Machine Testing accuracy: %0.6f\" % accuracy_score(Y_test, svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a support vector machine without any hyperparameter modifications also severly overfits with a training accuracy of 100%.  The test accuracy is concerning as it is exactly the same as `most frequent` baseline classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:32:09.177613Z",
     "start_time": "2018-12-15T23:32:09.140071Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Neural Net Training accuracy: 0.537559\n",
      "Baseline Neural Net Testing accuracy: 0.531469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(random_state=1234,max_iter=1000)\n",
    "mlp.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Baseline Neural Net Training accuracy: %0.6f\" % accuracy_score(Y_train, mlp.predict(X_train)))\n",
    "print(\"Baseline Neural Net Testing accuracy: %0.6f\" % accuracy_score(Y_test, mlp.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline MLP accuracy is not good.  It is 10% below the baseline accuracy of 63%.  It'll be interesting to see how much we can improve this or if there is simply not enough data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature preprocessing via Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:01:01.865341Z",
     "start_time": "2018-12-15T23:01:01.397282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for model LogisticRegression after standardizing features: 0.9859154929577465\n",
      "Test accuracy for model LogisticRegression after standardizing features: 0.993006993006993\n",
      "Train accuracy for model DecisionTreeClassifier after standardizing features: 1.0\n",
      "Test accuracy for model DecisionTreeClassifier after standardizing features: 0.958041958041958\n",
      "Train accuracy for model MLPClassifier after standardizing features: 0.9929577464788732\n",
      "Test accuracy for model MLPClassifier after standardizing features: 0.986013986013986\n",
      "Train accuracy for model SVC after standardizing features: 0.9835680751173709\n",
      "Test accuracy for model SVC after standardizing features: 0.986013986013986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "X_std = std_scaler.fit_transform(X)\n",
    "X_train_std = std_scaler.fit_transform(X_train)\n",
    "X_test_std = std_scaler.transform(X_test)\n",
    "\n",
    "# A little sanity check to see how models perform after scaling\n",
    "models = [logisticRegression, decisionTree, mlp, svm]\n",
    "for model in models:\n",
    "    # Warm start by default is off so by calling fit it \"retrains from scratch\" which is what we want\n",
    "    model.fit(X_train_std, Y_train)\n",
    "    model_name = model.__class__.__name__\n",
    "    train_accuracy = accuracy_score(Y_train, model.predict(X_train_std))\n",
    "    test_accuracy = accuracy_score(Y_test, model.predict(X_test_std))\n",
    "    print(\"Train accuracy for model {} after standardizing features: {}\".format(model_name, train_accuracy))\n",
    "    print(\"Test accuracy for model {} after standardizing features: {}\".format(model_name, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, standardizing the features results in a significant increase in both training and test accuracies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Cross Validation\n",
    "\n",
    "Here we are testing different percentiles (`[1, 2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]`) of the best features selected by ANOVA F-value.  For each percentile we run cross validation so we get the best parameters for that subset of features.  We do this for all four of our models with the end result giving us the best overall classifier with the best number of best features to inlcude and the respective optimal parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:40:56.180459Z",
     "start_time": "2018-12-15T22:36:43.876396Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile: 1, Classifier: LogisticRegression, Best Params: {'C': 0.001}, Accuracy: 0.908\n",
      "Percentile: 2, Classifier: LogisticRegression, Best Params: {'C': 0.001}, Accuracy: 0.908\n",
      "Percentile: 5, Classifier: LogisticRegression, Best Params: {'C': 0.01}, Accuracy: 0.930\n",
      "Percentile: 10, Classifier: LogisticRegression, Best Params: {'C': 0.01}, Accuracy: 0.946\n",
      "Percentile: 20, Classifier: LogisticRegression, Best Params: {'C': 100}, Accuracy: 0.953\n",
      "Percentile: 30, Classifier: LogisticRegression, Best Params: {'C': 10}, Accuracy: 0.955\n",
      "Percentile: 40, Classifier: LogisticRegression, Best Params: {'C': 1}, Accuracy: 0.944\n",
      "Percentile: 50, Classifier: LogisticRegression, Best Params: {'C': 100}, Accuracy: 0.941\n",
      "Percentile: 60, Classifier: LogisticRegression, Best Params: {'C': 0.1}, Accuracy: 0.969\n",
      "Percentile: 70, Classifier: LogisticRegression, Best Params: {'C': 0.1}, Accuracy: 0.977\n",
      "Percentile: 80, Classifier: LogisticRegression, Best Params: {'C': 0.1}, Accuracy: 0.977\n",
      "Percentile: 90, Classifier: LogisticRegression, Best Params: {'C': 0.1}, Accuracy: 0.977\n",
      "Percentile: 100, Classifier: LogisticRegression, Best Params: {'C': 0.1}, Accuracy: 0.981\n",
      "---\n",
      "Best Precentile: 100, Classifier: LogisticRegression, Best Params: {'C': 0.1}, Accuracy: 0.981\n",
      "\n",
      "\n",
      "Percentile: 1, Classifier: DecisionTreeClassifier, Best Params: {'max_depth': 1}, Accuracy: 0.904\n",
      "Percentile: 2, Classifier: DecisionTreeClassifier, Best Params: {'max_depth': 1}, Accuracy: 0.904\n",
      "Percentile: 5, Classifier: DecisionTreeClassifier, Best Params: {'min_samples_leaf': 2}, Accuracy: 0.930\n",
      "Percentile: 10, Classifier: DecisionTreeClassifier, Best Params: {'min_samples_leaf': 8}, Accuracy: 0.927\n",
      "Percentile: 20, Classifier: DecisionTreeClassifier, Best Params: {'min_samples_leaf': 8}, Accuracy: 0.923\n",
      "Percentile: 30, Classifier: DecisionTreeClassifier, Best Params: {'min_samples_leaf': 8}, Accuracy: 0.927\n",
      "Percentile: 40, Classifier: DecisionTreeClassifier, Best Params: {'max_depth': 4}, Accuracy: 0.920\n",
      "Percentile: 50, Classifier: DecisionTreeClassifier, Best Params: {'max_depth': 4}, Accuracy: 0.923\n",
      "Percentile: 60, Classifier: DecisionTreeClassifier, Best Params: {'min_samples_leaf': 2}, Accuracy: 0.927\n",
      "Percentile: 70, Classifier: DecisionTreeClassifier, Best Params: {'max_depth': 8}, Accuracy: 0.927\n",
      "Percentile: 80, Classifier: DecisionTreeClassifier, Best Params: {'max_depth': 4}, Accuracy: 0.927\n",
      "Percentile: 90, Classifier: DecisionTreeClassifier, Best Params: {'max_depth': 4}, Accuracy: 0.932\n",
      "Percentile: 100, Classifier: DecisionTreeClassifier, Best Params: {'max_depth': 4}, Accuracy: 0.932\n",
      "---\n",
      "Best Precentile: 90, Classifier: DecisionTreeClassifier, Best Params: {'max_depth': 4}, Accuracy: 0.932\n",
      "\n",
      "\n",
      "Percentile: 1, Classifier: MLPClassifier, Best Params: {'activation': 'relu'}, Accuracy: 0.906\n",
      "Percentile: 2, Classifier: MLPClassifier, Best Params: {'activation': 'relu'}, Accuracy: 0.906\n",
      "Percentile: 5, Classifier: MLPClassifier, Best Params: {'alpha': 10}, Accuracy: 0.934\n",
      "Percentile: 10, Classifier: MLPClassifier, Best Params: {'activation': 'logistic'}, Accuracy: 0.941\n",
      "Percentile: 20, Classifier: MLPClassifier, Best Params: {'activation': 'relu'}, Accuracy: 0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile: 30, Classifier: MLPClassifier, Best Params: {'hidden_layer_sizes': (3, 5, 3)}, Accuracy: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile: 40, Classifier: MLPClassifier, Best Params: {'activation': 'relu'}, Accuracy: 0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile: 50, Classifier: MLPClassifier, Best Params: {'activation': 'relu'}, Accuracy: 0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/ryanrouleau/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile: 60, Classifier: MLPClassifier, Best Params: {'activation': 'relu'}, Accuracy: 0.972\n",
      "Percentile: 70, Classifier: MLPClassifier, Best Params: {'activation': 'logistic'}, Accuracy: 0.977\n",
      "Percentile: 80, Classifier: MLPClassifier, Best Params: {'activation': 'identity'}, Accuracy: 0.979\n",
      "Percentile: 90, Classifier: MLPClassifier, Best Params: {'activation': 'logistic'}, Accuracy: 0.979\n",
      "Percentile: 100, Classifier: MLPClassifier, Best Params: {'alpha': 10}, Accuracy: 0.974\n",
      "---\n",
      "Best Precentile: 80, Classifier: MLPClassifier, Best Params: {'activation': 'identity'}, Accuracy: 0.979\n",
      "\n",
      "\n",
      "Percentile: 1, Classifier: SVC, Best Params: {'C': 0.1}, Accuracy: 0.908\n",
      "Percentile: 2, Classifier: SVC, Best Params: {'C': 0.1}, Accuracy: 0.908\n",
      "Percentile: 5, Classifier: SVC, Best Params: {'kernel': 'rbf'}, Accuracy: 0.941\n",
      "Percentile: 10, Classifier: SVC, Best Params: {'C': 0.1}, Accuracy: 0.944\n",
      "Percentile: 20, Classifier: SVC, Best Params: {'C': 10}, Accuracy: 0.951\n",
      "Percentile: 30, Classifier: SVC, Best Params: {'kernel': 'linear'}, Accuracy: 0.953\n",
      "Percentile: 40, Classifier: SVC, Best Params: {'C': 10}, Accuracy: 0.946\n",
      "Percentile: 50, Classifier: SVC, Best Params: {'C': 10}, Accuracy: 0.953\n",
      "Percentile: 60, Classifier: SVC, Best Params: {'kernel': 'rbf'}, Accuracy: 0.969\n",
      "Percentile: 70, Classifier: SVC, Best Params: {'kernel': 'rbf'}, Accuracy: 0.977\n",
      "Percentile: 80, Classifier: SVC, Best Params: {'C': 10}, Accuracy: 0.977\n",
      "Percentile: 90, Classifier: SVC, Best Params: {'kernel': 'rbf'}, Accuracy: 0.974\n",
      "Percentile: 100, Classifier: SVC, Best Params: {'C': 10}, Accuracy: 0.969\n",
      "---\n",
      "Best Precentile: 70, Classifier: SVC, Best Params: {'kernel': 'rbf'}, Accuracy: 0.977\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "WARNING: THIS MAY TAKE A WHILE TO RUN\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "\n",
    "\n",
    "model_to_possible_params = {}\n",
    "\n",
    "#Populate model_to_params:\n",
    "#Key is model_name, value is a dictionary mapping from parameter to a list of potential values\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    tunable_params = None\n",
    "    if model_name == 'LogisticRegression':\n",
    "        tunable_params = [{'C': [0.001, 0.01,0.1,1,10,100]}]\n",
    "    elif model_name == 'DecisionTreeClassifier':\n",
    "        tunable_params = [{'max_depth':[1,2,4,8]}, {'min_samples_leaf': [1,2,3,5,8]}]\n",
    "    elif model_name == 'SVC':\n",
    "        tunable_params = [{'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}, {'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "    else:\n",
    "        tunable_params = [{'activation':['identity', 'logistic', 'tanh', 'relu']}, \n",
    "                          {'alpha': [1e-04, 1e-03, 1e-02, 0.05, 1, 10]}, \n",
    "                          {'hidden_layer_sizes': [(3), (3,5), (3,5,3), (3,5,5)]}]\n",
    "    \n",
    "    model_to_possible_params[model_name] = tunable_params\n",
    "    \n",
    "percentiles = [1, 2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "#mapping from tuple (percentil, model) to cross validation score\n",
    "\n",
    "accuracy_results = {}\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    relevant_params = model_to_possible_params[model.__class__.__name__]\n",
    "    \n",
    "    # (best percentile, accuracy, model)\n",
    "    best_so_far = (None, -1, None)\n",
    "    \n",
    "    for percentile in percentiles:\n",
    "        selection = SelectPercentile(percentile=percentile, score_func=f_classif)\n",
    "        X_train_selected = selection.fit_transform(X_train_std, Y_train)\n",
    "        gs_classifier = GridSearchCV(model, relevant_params, cv=5, n_jobs=4)\n",
    "        gs_classifier.fit(X_train_selected, Y_train)\n",
    "        accuracy_results[(percentile, gs_classifier)] = gs_classifier.best_score_\n",
    "        \n",
    "        if gs_classifier.best_score_ > best_so_far[1]:\n",
    "            best_so_far = (percentile, gs_classifier.best_score_, gs_classifier) \n",
    "        \n",
    "        \n",
    "        print(\"Percentile: {}, Classifier: {}, Best Params: {}, Best Accuracy: {:.3f}\".format(\n",
    "            percentile,\n",
    "            model.__class__.__name__,\n",
    "            gs_classifier.best_params_,\n",
    "            gs_classifier.best_score_\n",
    "        ))\n",
    "        \n",
    "    print(\"---\")\n",
    "    print(\"Best Precentile: {}, Classifier: {}, Best Params: {}, Best Accuracy: {:.3f}\".format(\n",
    "        best_so_far[0],\n",
    "        model.__class__.__name__,\n",
    "        best_so_far[2].best_params_,\n",
    "        best_so_far[1]\n",
    "    ))\n",
    "    print(\"\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, more features results in a higher accuracy. The best models used 70%-100% of the best features selected by the F-value. This implies that there is little correlation between the features (little \"redundancy\" in feature set). We can do a quick check of the correlation matrix to see if any features are strongly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:27:15.114612Z",
     "start_time": "2018-12-15T22:27:14.805550Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "radius_mean                 1.000000      0.323782        0.997855   0.987357   \n",
      "texture_mean                0.323782      1.000000        0.329533   0.321086   \n",
      "perimeter_mean              0.997855      0.329533        1.000000   0.986507   \n",
      "area_mean                   0.987357      0.321086        0.986507   1.000000   \n",
      "smoothness_mean             0.170581     -0.023389        0.207278   0.177028   \n",
      "compactness_mean            0.506124      0.236702        0.556936   0.498502   \n",
      "concavity_mean              0.676764      0.302418        0.716136   0.685983   \n",
      "concave points_mean         0.822529      0.293464        0.850977   0.823269   \n",
      "symmetry_mean               0.147741      0.071401        0.183027   0.151293   \n",
      "fractal_dimension_mean     -0.311631     -0.076437       -0.261477  -0.283110   \n",
      "radius_se                   0.679090      0.275869        0.691765   0.732562   \n",
      "texture_se                 -0.097317      0.386358       -0.086761  -0.066280   \n",
      "perimeter_se                0.674172      0.281673        0.693135   0.726628   \n",
      "area_se                     0.735864      0.259845        0.744983   0.800086   \n",
      "smoothness_se              -0.222600      0.006614       -0.202694  -0.166777   \n",
      "compactness_se              0.206000      0.191975        0.250744   0.212583   \n",
      "concavity_se                0.194204      0.143293        0.228082   0.207660   \n",
      "concave points_se           0.376169      0.163851        0.407217   0.372320   \n",
      "symmetry_se                -0.104321      0.009127       -0.081629  -0.072497   \n",
      "fractal_dimension_se       -0.042641      0.054458       -0.005523  -0.019887   \n",
      "radius_worst                0.969539      0.352573        0.969476   0.962746   \n",
      "texture_worst               0.297008      0.912045        0.303038   0.287489   \n",
      "perimeter_worst             0.965137      0.358040        0.970387   0.959120   \n",
      "area_worst                  0.941082      0.343546        0.941550   0.959213   \n",
      "smoothness_worst            0.119616      0.077503        0.150549   0.123523   \n",
      "compactness_worst           0.413463      0.277830        0.455774   0.390410   \n",
      "concavity_worst             0.526911      0.301025        0.563879   0.512606   \n",
      "concave points_worst        0.744214      0.295316        0.771241   0.722017   \n",
      "symmetry_worst              0.163953      0.105008        0.189115   0.143570   \n",
      "fractal_dimension_worst     0.007066      0.119205        0.051019   0.003738   \n",
      "\n",
      "                         smoothness_mean  compactness_mean  concavity_mean  \\\n",
      "radius_mean                     0.170581          0.506124        0.676764   \n",
      "texture_mean                   -0.023389          0.236702        0.302418   \n",
      "perimeter_mean                  0.207278          0.556936        0.716136   \n",
      "area_mean                       0.177028          0.498502        0.685983   \n",
      "smoothness_mean                 1.000000          0.659123        0.521984   \n",
      "compactness_mean                0.659123          1.000000        0.883121   \n",
      "concavity_mean                  0.521984          0.883121        1.000000   \n",
      "concave points_mean             0.553695          0.831135        0.921391   \n",
      "symmetry_mean                   0.557775          0.602641        0.500667   \n",
      "fractal_dimension_mean          0.584792          0.565369        0.336783   \n",
      "radius_se                       0.301467          0.497473        0.631925   \n",
      "texture_se                      0.068406          0.046205        0.076218   \n",
      "perimeter_se                    0.296092          0.548905        0.660391   \n",
      "area_se                         0.246552          0.455653        0.617427   \n",
      "smoothness_se                   0.332375          0.135299        0.098564   \n",
      "compactness_se                  0.318943          0.738722        0.670279   \n",
      "concavity_se                    0.248396          0.570517        0.691270   \n",
      "concave points_se               0.380676          0.642262        0.683260   \n",
      "symmetry_se                     0.200774          0.229977        0.178009   \n",
      "fractal_dimension_se            0.283607          0.507318        0.449301   \n",
      "radius_worst                    0.213120          0.535315        0.688236   \n",
      "texture_worst                   0.036072          0.248133        0.299879   \n",
      "perimeter_worst                 0.238853          0.590210        0.729565   \n",
      "area_worst                      0.206718          0.509604        0.675987   \n",
      "smoothness_worst                0.805324          0.565541        0.448822   \n",
      "compactness_worst               0.472468          0.865809        0.754968   \n",
      "concavity_worst                 0.434926          0.816275        0.884103   \n",
      "concave points_worst            0.503053          0.815573        0.861323   \n",
      "symmetry_worst                  0.394309          0.510223        0.409464   \n",
      "fractal_dimension_worst         0.499316          0.687382        0.514930   \n",
      "\n",
      "                         concave points_mean  symmetry_mean  \\\n",
      "radius_mean                         0.822529       0.147741   \n",
      "texture_mean                        0.293464       0.071401   \n",
      "perimeter_mean                      0.850977       0.183027   \n",
      "area_mean                           0.823269       0.151293   \n",
      "smoothness_mean                     0.553695       0.557775   \n",
      "compactness_mean                    0.831135       0.602641   \n",
      "concavity_mean                      0.921391       0.500667   \n",
      "concave points_mean                 1.000000       0.462497   \n",
      "symmetry_mean                       0.462497       1.000000   \n",
      "fractal_dimension_mean              0.166917       0.479921   \n",
      "radius_se                           0.698050       0.303379   \n",
      "texture_se                          0.021480       0.128053   \n",
      "perimeter_se                        0.710650       0.313893   \n",
      "area_se                             0.690299       0.223970   \n",
      "smoothness_se                       0.027653       0.187321   \n",
      "compactness_se                      0.490424       0.421659   \n",
      "concavity_se                        0.439167       0.342627   \n",
      "concave points_se                   0.615634       0.393298   \n",
      "symmetry_se                         0.095351       0.449137   \n",
      "fractal_dimension_se                0.257584       0.331786   \n",
      "radius_worst                        0.830318       0.185728   \n",
      "texture_worst                       0.292752       0.090651   \n",
      "perimeter_worst                     0.855923       0.219169   \n",
      "area_worst                          0.809630       0.177193   \n",
      "smoothness_worst                    0.452753       0.426675   \n",
      "compactness_worst                   0.667454       0.473200   \n",
      "concavity_worst                     0.752399       0.433721   \n",
      "concave points_worst                0.910155       0.430297   \n",
      "symmetry_worst                      0.375744       0.699826   \n",
      "fractal_dimension_worst             0.368661       0.438413   \n",
      "\n",
      "                         fractal_dimension_mean           ...             \\\n",
      "radius_mean                           -0.311631           ...              \n",
      "texture_mean                          -0.076437           ...              \n",
      "perimeter_mean                        -0.261477           ...              \n",
      "area_mean                             -0.283110           ...              \n",
      "smoothness_mean                        0.584792           ...              \n",
      "compactness_mean                       0.565369           ...              \n",
      "concavity_mean                         0.336783           ...              \n",
      "concave points_mean                    0.166917           ...              \n",
      "symmetry_mean                          0.479921           ...              \n",
      "fractal_dimension_mean                 1.000000           ...              \n",
      "radius_se                              0.000111           ...              \n",
      "texture_se                             0.164174           ...              \n",
      "perimeter_se                           0.039830           ...              \n",
      "area_se                               -0.090170           ...              \n",
      "smoothness_se                          0.401964           ...              \n",
      "compactness_se                         0.559837           ...              \n",
      "concavity_se                           0.446630           ...              \n",
      "concave points_se                      0.341198           ...              \n",
      "symmetry_se                            0.345007           ...              \n",
      "fractal_dimension_se                   0.688132           ...              \n",
      "radius_worst                          -0.253691           ...              \n",
      "texture_worst                         -0.051269           ...              \n",
      "perimeter_worst                       -0.205151           ...              \n",
      "area_worst                            -0.231854           ...              \n",
      "smoothness_worst                       0.504942           ...              \n",
      "compactness_worst                      0.458798           ...              \n",
      "concavity_worst                        0.346234           ...              \n",
      "concave points_worst                   0.175325           ...              \n",
      "symmetry_worst                         0.334019           ...              \n",
      "fractal_dimension_worst                0.767297           ...              \n",
      "\n",
      "                         radius_worst  texture_worst  perimeter_worst  \\\n",
      "radius_mean                  0.969539       0.297008         0.965137   \n",
      "texture_mean                 0.352573       0.912045         0.358040   \n",
      "perimeter_mean               0.969476       0.303038         0.970387   \n",
      "area_mean                    0.962746       0.287489         0.959120   \n",
      "smoothness_mean              0.213120       0.036072         0.238853   \n",
      "compactness_mean             0.535315       0.248133         0.590210   \n",
      "concavity_mean               0.688236       0.299879         0.729565   \n",
      "concave points_mean          0.830318       0.292752         0.855923   \n",
      "symmetry_mean                0.185728       0.090651         0.219169   \n",
      "fractal_dimension_mean      -0.253691      -0.051269        -0.205151   \n",
      "radius_se                    0.715065       0.194799         0.719684   \n",
      "texture_se                  -0.111690       0.409003        -0.102242   \n",
      "perimeter_se                 0.697201       0.200371         0.721031   \n",
      "area_se                      0.757373       0.196497         0.761213   \n",
      "smoothness_se               -0.230691      -0.074743        -0.217304   \n",
      "compactness_se               0.204607       0.143003         0.260516   \n",
      "concavity_se                 0.186904       0.100241         0.226680   \n",
      "concave points_se            0.358127       0.086741         0.394999   \n",
      "symmetry_se                 -0.128121      -0.077473        -0.103753   \n",
      "fractal_dimension_se        -0.037488      -0.003195        -0.001000   \n",
      "radius_worst                 1.000000       0.359921         0.993708   \n",
      "texture_worst                0.359921       1.000000         0.365098   \n",
      "perimeter_worst              0.993708       0.365098         1.000000   \n",
      "area_worst                   0.984015       0.345842         0.977578   \n",
      "smoothness_worst             0.216574       0.225429         0.236775   \n",
      "compactness_worst            0.475820       0.360832         0.529408   \n",
      "concavity_worst              0.573975       0.368366         0.618344   \n",
      "concave points_worst         0.787424       0.359755         0.816322   \n",
      "symmetry_worst               0.243529       0.233027         0.269493   \n",
      "fractal_dimension_worst      0.093492       0.219122         0.138957   \n",
      "\n",
      "                         area_worst  smoothness_worst  compactness_worst  \\\n",
      "radius_mean                0.941082          0.119616           0.413463   \n",
      "texture_mean               0.343546          0.077503           0.277830   \n",
      "perimeter_mean             0.941550          0.150549           0.455774   \n",
      "area_mean                  0.959213          0.123523           0.390410   \n",
      "smoothness_mean            0.206718          0.805324           0.472468   \n",
      "compactness_mean           0.509604          0.565541           0.865809   \n",
      "concavity_mean             0.675987          0.448822           0.754968   \n",
      "concave points_mean        0.809630          0.452753           0.667454   \n",
      "symmetry_mean              0.177193          0.426675           0.473200   \n",
      "fractal_dimension_mean    -0.231854          0.504942           0.458798   \n",
      "radius_se                  0.751548          0.141919           0.287103   \n",
      "texture_se                -0.083195         -0.073658          -0.092439   \n",
      "perimeter_se               0.730713          0.130054           0.341919   \n",
      "area_se                    0.811408          0.125389           0.283257   \n",
      "smoothness_se             -0.182195          0.314457          -0.055558   \n",
      "compactness_se             0.199371          0.227394           0.678780   \n",
      "concavity_se               0.188353          0.168481           0.484858   \n",
      "concave points_se          0.342271          0.215351           0.452888   \n",
      "symmetry_se               -0.110343         -0.012662           0.060255   \n",
      "fractal_dimension_se      -0.022736          0.170568           0.390159   \n",
      "radius_worst               0.984015          0.216574           0.475820   \n",
      "texture_worst              0.345842          0.225429           0.360832   \n",
      "perimeter_worst            0.977578          0.236775           0.529408   \n",
      "area_worst                 1.000000          0.209145           0.438296   \n",
      "smoothness_worst           0.209145          1.000000           0.568187   \n",
      "compactness_worst          0.438296          0.568187           1.000000   \n",
      "concavity_worst            0.543331          0.518523           0.892261   \n",
      "concave points_worst       0.747419          0.547691           0.801080   \n",
      "symmetry_worst             0.209146          0.493838           0.614441   \n",
      "fractal_dimension_worst    0.079647          0.617624           0.810455   \n",
      "\n",
      "                         concavity_worst  concave points_worst  \\\n",
      "radius_mean                     0.526911              0.744214   \n",
      "texture_mean                    0.301025              0.295316   \n",
      "perimeter_mean                  0.563879              0.771241   \n",
      "area_mean                       0.512606              0.722017   \n",
      "smoothness_mean                 0.434926              0.503053   \n",
      "compactness_mean                0.816275              0.815573   \n",
      "concavity_mean                  0.884103              0.861323   \n",
      "concave points_mean             0.752399              0.910155   \n",
      "symmetry_mean                   0.433721              0.430297   \n",
      "fractal_dimension_mean          0.346234              0.175325   \n",
      "radius_se                       0.380585              0.531062   \n",
      "texture_se                     -0.068956             -0.119638   \n",
      "perimeter_se                    0.418899              0.554897   \n",
      "area_se                         0.385100              0.538166   \n",
      "smoothness_se                  -0.058298             -0.102007   \n",
      "compactness_se                  0.639147              0.483208   \n",
      "concavity_se                    0.662564              0.440472   \n",
      "concave points_se               0.549592              0.602450   \n",
      "symmetry_se                     0.037119             -0.030413   \n",
      "fractal_dimension_se            0.379975              0.215204   \n",
      "radius_worst                    0.573975              0.787424   \n",
      "texture_worst                   0.368366              0.359755   \n",
      "perimeter_worst                 0.618344              0.816322   \n",
      "area_worst                      0.543331              0.747419   \n",
      "smoothness_worst                0.518523              0.547691   \n",
      "compactness_worst               0.892261              0.801080   \n",
      "concavity_worst                 1.000000              0.855434   \n",
      "concave points_worst            0.855434              1.000000   \n",
      "symmetry_worst                  0.532520              0.502528   \n",
      "fractal_dimension_worst         0.686511              0.511114   \n",
      "\n",
      "                         symmetry_worst  fractal_dimension_worst  \n",
      "radius_mean                    0.163953                 0.007066  \n",
      "texture_mean                   0.105008                 0.119205  \n",
      "perimeter_mean                 0.189115                 0.051019  \n",
      "area_mean                      0.143570                 0.003738  \n",
      "smoothness_mean                0.394309                 0.499316  \n",
      "compactness_mean               0.510223                 0.687382  \n",
      "concavity_mean                 0.409464                 0.514930  \n",
      "concave points_mean            0.375744                 0.368661  \n",
      "symmetry_mean                  0.699826                 0.438413  \n",
      "fractal_dimension_mean         0.334019                 0.767297  \n",
      "radius_se                      0.094543                 0.049559  \n",
      "texture_se                    -0.128215                -0.045655  \n",
      "perimeter_se                   0.109930                 0.085433  \n",
      "area_se                        0.074126                 0.017539  \n",
      "smoothness_se                 -0.107342                 0.101480  \n",
      "compactness_se                 0.277878                 0.590973  \n",
      "concavity_se                   0.197788                 0.439329  \n",
      "concave points_se              0.143116                 0.310655  \n",
      "symmetry_se                    0.389402                 0.078079  \n",
      "fractal_dimension_se           0.111094                 0.591328  \n",
      "radius_worst                   0.243529                 0.093492  \n",
      "texture_worst                  0.233027                 0.219122  \n",
      "perimeter_worst                0.269493                 0.138957  \n",
      "area_worst                     0.209146                 0.079647  \n",
      "smoothness_worst               0.493838                 0.617624  \n",
      "compactness_worst              0.614441                 0.810455  \n",
      "concavity_worst                0.532520                 0.686511  \n",
      "concave points_worst           0.502528                 0.511114  \n",
      "symmetry_worst                 1.000000                 0.537848  \n",
      "fractal_dimension_worst        0.537848                 1.000000  \n",
      "\n",
      "[30 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = data_cleaned.corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall best and worst models from Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:48:11.190383Z",
     "start_time": "2018-12-15T22:48:11.180475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall best model according to cross validation results was: LogisticRegression\n",
      " with params {'C': 0.1}\n",
      " using 100% of the best features\n",
      " with CV accuracy of 0.9812\n",
      "\n",
      "The overall worst model according to cross validation results was: DecisionTreeClassifier\n",
      " with params {'max_depth': 1}\n",
      " using 1% of the best features\n",
      " with CV of accuracy of 0.9038\n"
     ]
    }
   ],
   "source": [
    "sorted_by_accuracy = sorted(accuracy_results.items(), key=lambda kv: kv[1])\n",
    "\n",
    "# best worst models are tuple ((percentile, model), accuracy)\n",
    "best_model_tup = sorted_by_accuracy[-1]\n",
    "worst_model_tup = sorted_by_accuracy[0]\n",
    "\n",
    "print(\"The overall best model according to cross validation results was: {}\\n with params {}\\n using {}% of the best features\\n with CV accuracy of {:.4f}\".format(\n",
    "    best_model_tup[0][1].estimator.__class__.__name__,\n",
    "    best_model_tup[0][1].best_params_,\n",
    "    best_model_tup[0][0],\n",
    "    best_model_tup[1]\n",
    "))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"The overall worst model according to cross validation results was: {}\\n with params {}\\n using {}% of the best features\\n with CV of accuracy of {:.4f}\".format(\n",
    "    worst_model_tup[0][1].estimator.__class__.__name__,\n",
    "    worst_model_tup[0][1].best_params_,\n",
    "    worst_model_tup[0][0],\n",
    "    worst_model_tup[1]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T22:50:02.505117Z",
     "start_time": "2018-12-15T22:50:02.493319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model's test accuracy is: 99.3007%\n"
     ]
    }
   ],
   "source": [
    "best_model = best_model_tup[0][1].estimator\n",
    "best_model.fit(X_train_std, Y_train)\n",
    "best_acc = accuracy_score(Y_test, best_model.predict(X_test_std))\n",
    "print(\"The best model's test accuracy is: {:.4f}%\".format(best_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our highest test accuracy was **`99.3%`** with **`Logistic Regression`** using **`100% of features`** and hyperparameter **`C=0.1`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Error analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:01:09.539069Z",
     "start_time": "2018-12-15T23:01:09.527813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[355   2]\n",
      " [  6 206]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = best_model.predict(X_std)\n",
    "\n",
    "\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are predicting the model on all of our data as only one sample was misclassified using just the test data.\n",
    "\n",
    "We can see that the classifier is 3x (if we can conclude that with such little data) more likely to predict a sample as NOT breast cancaer if it actualy IS breast cancer vs. predicting a sample IS breast cancer if it's actually NOT breast cancer.\n",
    "\n",
    "In this use case it might be useful to modify our model so that it penalizes false negatives and allow more false positives so it's not predicted that people don't have breast cancer when in reality they do.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpeting what the classifier is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:16:46.353937Z",
     "start_time": "2018-12-15T23:16:46.337177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Weight', 'Feature Name')\n",
      "--------------------------------\n",
      "(0.00016324339113484281, 'concavity_se')\n",
      "(0.11605046247421666, 'smoothness_mean')\n",
      "(-0.12762966852250768, 'compactness_worst')\n",
      "(0.1305932122497972, 'symmetry_mean')\n",
      "(0.15186035604779519, 'concave points_se')\n",
      "(-0.25024500310196252, 'compactness_mean')\n",
      "(-0.26432970521766735, 'fractal_dimension_mean')\n",
      "(0.27200613356879, 'fractal_dimension_worst')\n",
      "(0.40002441449523313, 'perimeter_mean')\n",
      "(0.40254829821648508, 'radius_mean')\n",
      "(-0.42851346178853988, 'symmetry_se')\n",
      "(0.46461075894386478, 'area_mean')\n",
      "(0.46713405190813262, 'smoothness_se')\n",
      "(-0.47339531085328279, 'texture_se')\n",
      "(0.48550796200685459, 'texture_mean')\n",
      "(0.62829707346847874, 'perimeter_se')\n",
      "(0.7057089333843366, 'smoothness_worst')\n",
      "(-0.7073199363992122, 'fractal_dimension_se')\n",
      "(0.81332054944967513, 'perimeter_worst')\n",
      "(0.83018068041975379, 'symmetry_worst')\n",
      "(0.84403023566214486, 'concave points_mean')\n",
      "(0.92607872367038546, 'concavity_worst')\n",
      "(0.93187317857591812, 'concavity_mean')\n",
      "(0.93641908742309288, 'concave points_worst')\n",
      "(-0.94920710268952346, 'compactness_se')\n",
      "(0.9599223906213995, 'area_worst')\n",
      "(0.98272752142052511, 'radius_worst')\n",
      "(0.99283035777177964, 'area_se')\n",
      "(1.0787517927647727, 'radius_se')\n",
      "(1.4157932650795066, 'texture_worst')\n"
     ]
    }
   ],
   "source": [
    "labels = list(data_cleaned[data_cleaned.columns.difference([\"diagnosis\"])].columns.values)\n",
    "coefs_and_labels = list(zip(best_model.coef_[0], labels))\n",
    "sorted_coefs_and_labels = sorted(coefs_and_labels, key=lambda tup: abs(tup[0]))\n",
    "\n",
    "print((\"Weight\", \"Feature Name\"))\n",
    "print(\"--------------------------------\")\n",
    "for tup in sorted_coefs_and_labels:\n",
    "    print(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we print the sorted coefficients of our best model from least significant to most significant along with the corresponding human readable feature name.  Note that since we standardized our data we can directly compare the weights of features.  \n",
    "\n",
    "The 5 **most significant** features are:\n",
    "1. `texture_worst (1.416)` - \"worst\" or largest mean value for standard deviation of gray-scale values\n",
    "2. `radius_se (1.079)` - standard error for the mean of distances from center to points on the perimeter\n",
    "3. `area_se (0.993)` - \n",
    "4. `radius_worst (0.983)` - \"worst\" or largest mean value for mean of distances from center to points on the perimeter\n",
    "5. `area_worst (0.960)` - \n",
    "\n",
    "The 5 **least significant** features are:\n",
    "1. `concavity_se (0.000)` - \"standard error for severity of concave portions of the contour\"\n",
    "2. `smoothness_mean (0.116)` - \"standard error for local variation in radius lengths\"\n",
    "3. `compactness_worst (-0.128)` - \"worst\" or largest mean value for perimeter^2 / area - 1.0\n",
    "4. `symmetry_mean (0.130)` - \n",
    "5. `concave_points_se (0.152)` - mean for number of concave portions of the contour\n",
    "\n",
    "Overall, significantly more features are weighted positively than negatively and in fact the most significant 5 features are all positive.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
